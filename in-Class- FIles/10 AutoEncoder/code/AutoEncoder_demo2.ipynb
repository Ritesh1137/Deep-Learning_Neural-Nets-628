{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "(x_train, _), (x_test, _) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print(x_train.shape) \n",
    "print(x_test.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compression factor: 24.5\n",
      "WARNING:tensorflow:From /anaconda3/envs/deep_learning/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 784)               25872     \n",
      "=================================================================\n",
      "Total params: 50,992\n",
      "Trainable params: 50,992\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# input dimension = 784\n",
    "input_dim = x_train.shape[1]\n",
    "encoding_dim = 32\n",
    "\n",
    "compression_factor = float(input_dim) / encoding_dim\n",
    "print(\"Compression factor: %s\" % compression_factor)\n",
    "\n",
    "autoencoder = Sequential()\n",
    "autoencoder.add(\n",
    "    Dense(encoding_dim, input_shape=(input_dim,), activation='relu')\n",
    ")\n",
    "autoencoder.add(\n",
    "    Dense(input_dim, activation='sigmoid')\n",
    ")\n",
    "\n",
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                25120     \n",
      "=================================================================\n",
      "Total params: 25,120\n",
      "Trainable params: 25,120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_img = Input(shape=(input_dim,))\n",
    "encoder_layer = autoencoder.layers[0]\n",
    "encoder = Model(input_img, encoder_layer(input_img))\n",
    "\n",
    "encoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/deep_learning/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2794 - val_loss: 0.1918\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.1721 - val_loss: 0.1537\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1443 - val_loss: 0.1341\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.1290 - val_loss: 0.1221\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.1190 - val_loss: 0.1136\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.1118 - val_loss: 0.1076\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.1066 - val_loss: 0.1033\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.1027 - val_loss: 0.0999\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0999 - val_loss: 0.0974\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0978 - val_loss: 0.0958\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0965 - val_loss: 0.0947\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0956 - val_loss: 0.0939\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0950 - val_loss: 0.0935\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0946 - val_loss: 0.0932\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0943 - val_loss: 0.0929\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0941 - val_loss: 0.0927\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.0939 - val_loss: 0.0925\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.0937 - val_loss: 0.0924\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.0936 - val_loss: 0.0923\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.0935 - val_loss: 0.0922\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.0934 - val_loss: 0.0922\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0933 - val_loss: 0.0922\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.0932 - val_loss: 0.0920\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0932 - val_loss: 0.0920\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.0930 - val_loss: 0.0919\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0930 - val_loss: 0.0917\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.0930 - val_loss: 0.0919\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.0929 - val_loss: 0.0917\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.0929 - val_loss: 0.0917\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.0929 - val_loss: 0.0917\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.0929 - val_loss: 0.0917\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.0928 - val_loss: 0.0917\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.0928 - val_loss: 0.0916\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.0928 - val_loss: 0.0916\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.0928 - val_loss: 0.0917\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.0928 - val_loss: 0.0916\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0927 - val_loss: 0.0916\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.0927 - val_loss: 0.0916\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.0927 - val_loss: 0.0915\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0927 - val_loss: 0.0916\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0927 - val_loss: 0.0916\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0927 - val_loss: 0.0915\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.0927 - val_loss: 0.0915\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0926 - val_loss: 0.0915\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.0926 - val_loss: 0.0915\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0926 - val_loss: 0.0915\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0926 - val_loss: 0.0915\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.0926 - val_loss: 0.0915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10796b2b0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x288 with 30 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_images = 10\n",
    "np.random.seed(42)\n",
    "random_test_images = np.random.randint(x_test.shape[0], size=num_images)\n",
    "\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = autoencoder.predict(x_test)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(18, 4))\n",
    "\n",
    "for i, image_idx in enumerate(random_test_images):\n",
    "    # plot original image\n",
    "    ax = plt.subplot(3, num_images, i + 1)\n",
    "    plt.imshow(x_test[image_idx].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    # plot encoded image\n",
    "    ax = plt.subplot(3, num_images, num_images + i + 1)\n",
    "    plt.imshow(encoded_imgs[image_idx].reshape(8, 4))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # plot reconstructed image\n",
    "    ax = plt.subplot(3, num_images, 2*num_images + i + 1)\n",
    "    plt.imshow(decoded_imgs[image_idx].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 784)               101136    \n",
      "=================================================================\n",
      "Total params: 222,384\n",
      "Trainable params: 222,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder = Sequential()\n",
    "\n",
    "# Encoder Layers\n",
    "autoencoder.add(Dense(4 * encoding_dim, input_shape=(input_dim,), activation='relu'))\n",
    "autoencoder.add(Dense(2 * encoding_dim, activation='relu'))\n",
    "autoencoder.add(Dense(encoding_dim, activation='relu'))\n",
    "\n",
    "# Decoder Layers\n",
    "autoencoder.add(Dense(2 * encoding_dim, activation='relu'))\n",
    "autoencoder.add(Dense(4 * encoding_dim, activation='relu'))\n",
    "autoencoder.add(Dense(input_dim, activation='sigmoid'))\n",
    "\n",
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 32)                2080      \n",
      "=================================================================\n",
      "Total params: 110,816\n",
      "Trainable params: 110,816\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_img = Input(shape=(input_dim,))\n",
    "encoder_layer1 = autoencoder.layers[0]\n",
    "encoder_layer2 = autoencoder.layers[1]\n",
    "encoder_layer3 = autoencoder.layers[2]\n",
    "encoder = Model(input_img, encoder_layer3(encoder_layer2(encoder_layer1(input_img))))\n",
    "\n",
    "encoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 784)               101136    \n",
      "=================================================================\n",
      "Total params: 111,568\n",
      "Trainable params: 111,568\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder_layer1=autoencoder.layers[-3]\n",
    "decoder_layer2=autoencoder.layers[-2]\n",
    "decoder_layer3=autoencoder.layers[-1]\n",
    "decoder=Model(encoded_input, decoder_layer3(decoder_layer2(decoder_layer1(encoded_input))))\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(encoded_input):\n",
    "    h=Dense(inter_encoding_dim, activation='relu')(encoded_input)\n",
    "    decoded= Dense(input_dim, activation='sigmoid')(h)\n",
    "    return decoded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Autoencoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For image convolution, we first need to recover the orignal image size\n",
    "x_train = x_train.reshape((len(x_train), 28, 28, 1))\n",
    "x_test = x_test.reshape((len(x_test), 28, 28, 1))\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 14, 14, 8)         1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 7, 7, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 4, 4, 8)           584       \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 4, 4, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 4, 4, 8)           584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2 (None, 8, 8, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 8, 8, 8)           584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2 (None, 16, 16, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 14, 14, 16)        1168      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_9 (UpSampling2 (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 28, 28, 1)         145       \n",
      "=================================================================\n",
      "Total params: 4,385\n",
      "Trainable params: 4,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape\n",
    "from keras import regularizers\n",
    "autoencoder = Sequential()\n",
    "\n",
    "# Encoder Layers\n",
    "autoencoder.add(Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=x_train.shape[1:]))\n",
    "autoencoder.add(MaxPooling2D((2, 2), padding='same'))\n",
    "autoencoder.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "autoencoder.add(MaxPooling2D((2, 2), padding='same'))\n",
    "autoencoder.add(Conv2D(8, (3, 3), strides=(2,2), activation='relu', padding='same'))\n",
    "\n",
    "# Flatten encoding for visualization\n",
    "autoencoder.add(Flatten())\n",
    "autoencoder.add(Reshape((4, 4, 8)))\n",
    "\n",
    "# Decoder Layers\n",
    "autoencoder.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "autoencoder.add(UpSampling2D((2, 2)))\n",
    "autoencoder.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "autoencoder.add(UpSampling2D((2, 2)))\n",
    "autoencoder.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "autoencoder.add(UpSampling2D((2, 2)))\n",
    "autoencoder.add(Conv2D(1, (3, 3), activation='sigmoid', padding='same'))\n",
    "\n",
    "autoencoder.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15_input (InputLayer) (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 14, 14, 8)         1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 7, 7, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 4, 4, 8)           584       \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 128)               0         \n",
      "=================================================================\n",
      "Total params: 1,904\n",
      "Trainable params: 1,904\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder = Model(inputs=autoencoder.input, outputs=autoencoder.get_layer('flatten_3').output)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 57s 942us/step - loss: 0.2088 - val_loss: 0.1332\n",
      "Epoch 2/100\n",
      "28800/60000 [=============>................] - ETA: 30s - loss: 0.1284"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-8d39e3e65261>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                 validation_data=(x_test, x_test))\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/deep_learning/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/envs/deep_learning/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/deep_learning/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/deep_learning/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/deep_learning/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=100,\n",
    "                batch_size=128,\n",
    "                validation_data=(x_test, x_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denoising Images with the Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_noisy = x_train + np.random.normal(loc=0.0, scale=0.5, size=x_train.shape)\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "\n",
    "x_test_noisy = x_test + np.random.normal(loc=0.0, scale=0.5, size=x_test.shape)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
    "\n",
    "num_images = 10\n",
    "np.random.seed(42)\n",
    "random_test_images = np.random.randint(x_test.shape[0], size=num_images)\n",
    "\n",
    "# Denoise test images\n",
    "x_test_denoised = autoencoder.predict(x_test_noisy)\n",
    "\n",
    "plt.figure(figsize=(18, 4))\n",
    "\n",
    "for i, image_idx in enumerate(random_test_images):\n",
    "    # plot original image\n",
    "    ax = plt.subplot(2, num_images, i + 1)\n",
    "    plt.imshow(x_test_noisy[image_idx].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    # plot reconstructed image\n",
    "    ax = plt.subplot(2, num_images, num_images + i + 1)\n",
    "    plt.imshow(x_test_denoised[image_idx].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Autoencoder - Revisit\n",
    "This time, we use (x_train_noisy, x_train) as training data and (x_test_noisy, x_test) as validation data. In doing so, were teaching the autoencoder how to denoise the input images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 7, 7, 32)          9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_10 (UpSampling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_11 (UpSampling (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 28, 28, 1)         289       \n",
      "=================================================================\n",
      "Total params: 28,353\n",
      "Trainable params: 28,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder = Sequential()\n",
    "\n",
    "# Encoder Layers\n",
    "autoencoder.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=x_train.shape[1:]))\n",
    "autoencoder.add(MaxPooling2D((2, 2), padding='same'))\n",
    "autoencoder.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "autoencoder.add(MaxPooling2D((2, 2), padding='same'))\n",
    "\n",
    "# Decoder Layers\n",
    "autoencoder.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "autoencoder.add(UpSampling2D((2, 2)))\n",
    "autoencoder.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "autoencoder.add(UpSampling2D((2, 2)))\n",
    "autoencoder.add(Conv2D(1, (3, 3), activation='sigmoid', padding='same'))\n",
    "\n",
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
